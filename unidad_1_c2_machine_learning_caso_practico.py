# -*- coding: utf-8 -*-
"""Unidad_1_C2_Machine_Learning_caso_practico.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DIvbM7f_nh5UoNEgv4xJ__crq3dnW3D2

**Caso práctico 1**

**Objetivos:**

1. Demostrar comprension de los conceptos técnicos relevantes y su aplicación en el caso práctico.

2. Demostrar la capacidad de aplicar conceptos técnicos aprendidos en situaciones prácticas del mundo real.

3. Presentar una respuesta clara, organizada y correctamente documentada.

4. Demostrar habilidades para identificar, analuzar y resolver problemas técnicos de manera eficaz.

**Descripción del caso práctico 1**

En la industria energética, la detección de fraude es un desafío significativo que puede tener consecuencias financieras y operativas graves para las empresas proveedoras de servicios y, en última instancia, para los consumidores. El fraude energético puede manifestarse de diversas formas, como el robo de electricidad o gas, manipulación de medidores, conexiones ilegales, entre otras prácticas fraudulentas. Estas actividades no solo representan pérdidas económicas para las empresas, sino que también pueden generar riesgos de seguridad y calidad del servicio.

En respuesta a estos desafíos, las empresas de servicios energéticos están recurriendo cada vez más a la Inteligencia Artificial para desarrollar sistemas avanzados de detección de fraude energético. Estos sistemas utilizan algoritmos de aprendizaje automático y análisis de datos para identificar patrones anómalos y comportamientos sospechosos que podrían indicar la presencia de fraude. La detección temprana y precisa de tales actividades ilegales permite a las empresas tomar medidas preventivas y correctivas de manera oportuna, protegiendo así sus ingresos y manteniendo la integridad de sus operaciones.

Suponemos que tenemos un conjunto de datos que contiene la siguiente información:

**• Datos del cliente:**

ID del cliente, nombre del cliente, dirección, tipo de cliente (residencial, comercial, industrial), historial de consumo energético (promedio de consumo mensual, patrones de consumo, etc.)

**• Datos de consumo energético:**

Lecturas de medidores (electricidad, gas, etc.), fechas y horas de las lecturas, consumo energético en kWh o unidades equivalentes, tipo de medidor (analógico, digital, inteligente), información sobre picos de consumo y fluctuaciones inusuales, etc.

**• Datos de facturación:**

Monto de la factura, fecha de emisión de la factura, detalles de los cargos (tarifas, impuestos, recargos, etc.), estado de pago (pagado, vencido, pendiente), información sobre discrepancias entre el consumo registrado y el facturado, etc.

**• Datos geográficos:**

Ubicación del cliente (latitud y longitud), zona geográfica (urbana, rural), información demográfica sobre la ubicación del cliente, etc.

**• Datos de comportamiento y anomalías:**

Patrones de consumo anormales (consumo extremadamente alto o bajo en comparación con el promedio), variaciones significativas en el consumo en un período de tiempo específico, número de conexiones activas en una ubicación, historial de pagos, etc.

**• Datos de inspección y denuncias:**

Información sobre inspecciones realizadas por técnicos de la empresa energética, denuncias de fraude o irregularidades reportadas por clientes u otros organismos, etc.

**• Etiquetas de fraude:**

Etiqueta binaria que indica si se ha identificado fraude en el consumo energético del cliente  Justifica el planteamiento analítico que utilizarías para identificar los clientes con mayor probabilidad de fraude y así dirigir las inspecciones a los hogares de dichos clientes.

**Metodologia**

Para la resolucion del caso practico se ha elegido la implementacion de EDA (Exploratory Data Analysis)

Porque esta metodologia?

Esta metodologia ayuda de manera eficiente a analizar set de datos y descubrir patrones, anomalias e hipotesis. EDA es regularmente usado para entender relaciones entre variables en un set de datos y para determinar si las tecnicas estadisticas son las adecuadas.

**Resolucion del caso practico.**

Para realizar este caso practico y con el objetivo de demostrar y argumentar los pasos a ejecutar, se decidio recrear un set de datos aleatorio en Google Colab usando las librerias disponibles para el uso de datos exploratorios con el lenguaje python.

**Set de datos:**

    1. 'Customer_ID': range(1, 11),
    2. 'Customer_Type': ['Residential', 'Commercial', 'Industrial', 'Residential', 'Commercial','Industrial', 'Residential', 'Commercial', 'Industrial', 'Residential'],
    3. 'Avg_Monthly_Consumption': [120, 2000, 5000, 130, 2100, 4800, 110, 2200, 5050, 125],
    4. 'Meter_Type': ['Analog', 'Digital', 'Smart', 'Analog', 'Digital', 'Smart', 'Analog', 'Digital', 'Smart', 'Analog'],
    5. 'Consumption_Peaks': ['High', 'Moderate', 'Very High', 'Low', 'High', 'Very High', 'Moderate', 'High', 'Very High', 'Low'],
    6. 'Billing_Discrepancy': ['No', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'No', 'No'],
    7. 'Geo_Area': ['Urban', 'Urban', 'Rural', 'Urban', 'Urban', 'Rural', 'Urban', 'Urban', 'Rural', 'Rural'],
    8. 'Anomaly_Score': [0.12, 0.45, 0.88, 0.04, 0.53, 0.90, 0.10, 0.67, 0.92, 0.09],
    9. 'Payment_History': ['Late', 'Paid on time', 'Overdue', 'Paid on time', 'Overdue',
                        'Paid on time', 'Late', 'Overdue', 'Paid on time', 'Paid on time'],
    10. 'Fraud_Label': [0, 1, 0, 0, 1, 1, 0, 1, 0, 0]

Este set de datos cuenta con los siguientes campos:

**Customer ID, Customer_Type, Commercial, Average_Monthly_Consumption, Meter_Type, Consumption_Peaks, Billing_Discrepancy, Geo_Area, Anomaly_Score, Payment_History, Fraud_Label**

**Ingenieria de datos:**

1. **ID de cliente**
**Descripción:** Un identificador único para cada cliente.

2. **Tipo_de_cliente**
**Descripción:** Indica el segmento de clientes (p. ej., residencial, comercial, industrial).

**Ingeniería de características:**

Se realiza codificando como características categóricas mediante codificación one-hot o codificación de etiquetas.

Esto permite considerar agrupar tipos de clientes similares si hay muchas categorías únicas (p. ej., combinar Residencial y Pequeñas empresas en un solo grupo si los comportamientos son similares).

3. **Consumo_mensual_promedio**
**Descripción:**
Representa el consumo de energía promedio del cliente por mes.

**Ingeniería de características:**
Su objetivo es normalizar o estandarizar los valores para uniformidad.

**Crear características derivadas:**

*   **Desviación de la media del segmento:** Su propósito es comparar el consumo del cliente con el promedio para su tipo de cliente.

**Variabilidad del consumo:** Ejecutar mediante medidas estadísticas (p. ej., desviación estándar) a lo largo de los meses para capturar patrones de uso irregulares.

4. **Meter_Type**
**Descripción:** Indicar el tipo de medidor utilizado (p. ej., analógico, digital, inteligente).

**Ingeniería de características:**
Realizar mediante codificación one-hot.

Esto permite agregar características binarias que indiquen si un cliente está utilizando un medidor inteligente (1 si es inteligente, 0 en caso contrario), ya que pueden correlacionarse con un menor fraude debido a un mejor monitoreo.

5. **Consumption_Peaks**
**Descripción:** Captura patrones de consumo de energía pico (p. ej., alto, moderado, muy alto, bajo).

**Ingeniería de características:**
Codificar categóricamente con codificación one-hot.

Creando una característica binaria que indique si un cliente tiene picos extremos (1 para alto/muy alto, 0 en caso contrario), ya que dichos patrones pueden correlacionarse con un comportamiento fraudulento.

6. **Billing_Discrepancy**

**Descripción:** Su propósito es indicar si existe una discrepancia entre el consumo registrado y facturado (Sí/No).

**Ingeniería de características:**
Codificar como una variable binaria (1 para Sí, 0 para No).

Permite derivar una característica acumulativa para la frecuencia de discrepancias a lo largo del tiempo si hay datos históricos disponibles.

7. **Geo_Area**
**Descripción:** Clasificar la región geográfica del cliente (p. ej., Urbana, Rural).

**Ingeniería de características:**
Codificar categóricamente con codificación one-hot.

Su propósito es proveer una puntuación de riesgo de fraude basada en datos históricos o correlaciones conocidas entre tasas de fraude y áreas geográficas.

8. **Anomaly_Score**
**Descripción:** Es una medida numérica de comportamiento inusual o extremo de uso de energía.

Se puede combinar con otros campos (p. ej., Billing_Discrepancy, Consumption_Peaks) para crear características de interacción que resalten anomalías extremas.

9. **Payment_History**
**Descripción:** Este campo indica el comportamiento de pago (p. ej., Pagado a tiempo, Tarde, Vencido).

**Ingeniería de características:**
Codificar con codificación one-hot.

**Se pueden obtener características como:**

1.   **Frecuencia de demora de pago:** contar la cantidad de pagos atrasados ​​o vencidos.
2.   **Monto vencido acumulado:** agregue los pagos vencidos si hay datos monetarios disponibles.
3.   **Puntuación de consistencia de pago:** una puntuación personalizada basada en patrones de pago históricos.


10. **Fraud_Label**
**Descripción:** la variable de destino, que indica si se ha detectado fraude (1 para fraude, 0 para ausencia de fraude).

**Acción:** consérvela como variable dependiente para el aprendizaje supervisado.

# **Importar librerias**
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.preprocessing import StandardScaler, LabelEncoder

"""# **Simular Set de Datos**"""

# Simulating a small dataset
data = {
    'Customer_ID': range(1, 11),
    'Customer_Type': ['Residential', 'Commercial', 'Industrial', 'Residential', 'Commercial',
                      'Industrial', 'Residential', 'Commercial', 'Industrial', 'Residential'],
    'Avg_Monthly_Consumption': [120, 2000, 5000, 130, 2100, 4800, 110, 2200, 5050, 125],
    'Meter_Type': ['Analog', 'Digital', 'Smart', 'Analog', 'Digital', 'Smart', 'Analog', 'Digital', 'Smart', 'Analog'],
    'Consumption_Peaks': ['High', 'Moderate', 'Very High', 'Low', 'High', 'Very High', 'Moderate', 'High', 'Very High', 'Low'],
    'Billing_Discrepancy': ['No', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'No', 'No'],
    'Geo_Area': ['Urban', 'Urban', 'Rural', 'Urban', 'Urban', 'Rural', 'Urban', 'Urban', 'Rural', 'Rural'],
    'Anomaly_Score': [0.12, 0.45, 0.88, 0.04, 0.53, 0.90, 0.10, 0.67, 0.92, 0.09],
    'Payment_History': ['Late', 'Paid on time', 'Overdue', 'Paid on time', 'Overdue',
                        'Paid on time', 'Late', 'Overdue', 'Paid on time', 'Paid on time'],
    'Fraud_Label': [0, 1, 0, 0, 1, 1, 0, 1, 0, 0]
}

# Convert to DataFrame
df = pd.DataFrame(data)

"""# **Preprocesamiento de Datos**

Codificar variables categóricas: convertir características categóricas en formatos numéricos.

Escalar características numéricas: normalizar características para lograr un escalamiento consistente.


"""

# Encode categorical variables
df = pd.get_dummies(df, columns=['Customer_Type', 'Meter_Type', 'Consumption_Peaks',
                                 'Billing_Discrepancy', 'Geo_Area', 'Payment_History'], drop_first=True)

# Define features and target variable
X = df.drop(['Customer_ID', 'Fraud_Label'], axis=1)  # Drop ID and target label from features
y = df['Fraud_Label']

# Standardize numerical features
scaler = StandardScaler()
X[['Avg_Monthly_Consumption', 'Anomaly_Score']] = scaler.fit_transform(X[['Avg_Monthly_Consumption', 'Anomaly_Score']])

"""# **Particionar el set de datos**

Dividir los datos en conjunto de entrenamiento y de prueba.
"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

"""# **Entrenar el modelo**"""

# Initialize and train Random Forest model
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

"""En este paso evaluamos el modelo utilizando el conjunto de pruebas, la matriz de confusión y el informe de clasificación."""

# Make predictions
y_pred = model.predict(X_test)

# Display confusion matrix and classification report
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

"""Identifique qué características contribuyen más a la detección de fraudes."""

# Display feature importance
feature_importance = pd.DataFrame({'Feature': X.columns, 'Importance': model.feature_importances_})
print("\nFeature Importance:")
print(feature_importance.sort_values(by='Importance', ascending=False))

"""# **Interpretacion de resultados**

**Información clave de la importancia de las funciones
Principales funciones que contribuyen:**

**Meter_Type_Digital (0,264):** los clientes con medidores digitales están fuertemente asociados con la detección de fraudes. Esto podría indicar una relación entre la manipulación de medidores y los medidores digitales.

**Billing_Discrepancy_Yes (0,198):** las discrepancias entre el consumo facturado y registrado son un fuerte indicador de comportamiento fraudulento, como se esperaba.

**Avg_Monthly_Consumption (0,151):** los patrones de consumo promedio inusuales (muy altos o muy bajos) juegan un papel importante en la detección de fraudes.
Contribuciones moderadas:

**Customer_Type_Residential (0,116):** el fraude puede ser más probable entre los clientes residenciales en comparación con otros tipos de clientes.

**Anomaly_Score (0,076):** los puntajes de anomalía altos se correlacionan con el comportamiento fraudulento, lo que refuerza la importancia de rastrear irregularidades en el consumo.

**Payment_History_Overdue (0,069):** Los pagos vencidos agregan un poder predictivo valioso, probablemente reflejando problemas financieros que pueden estar relacionados con actividades fraudulentas.

# **Contribuciones bajas:**

**Consumption_Peaks_Low (0,029):**
Los picos de consumo bajos son menos predictivos, pero aún así aportan algo de información.

**Geo_Area_Urban (0,022):**
Las áreas urbanas muestran una relevancia menor para la detección de fraude, posiblemente debido a diferencias en el monitoreo o la densidad de población.

**Consumption_Peaks_Very High (0,020):**
Los picos muy altos impactan levemente en la detección de fraude, pero su importancia es menor a la esperada.

**# Características que menos contribuyen:**

**Meter_Type_Smart (0,009):**
Los medidores inteligentes tienen una relación mínima con la detección de fraude, probablemente debido a mejores capacidades de monitoreo.

**Consumption_Peaks_Moderate (0,002):**
Los picos de consumo moderados casi no brindan valor predictivo.

# **Acciones recomendadas a realizar basadas en los resultados**

**Recomendaciones para la implementación de casos prácticos
Concéntrese en las características de alto impacto:**

Segun los resultados es apropiado incluir Meter_Type_Digital, Billing_Discrepancy_Yes y Avg_Monthly_Consumption como características principales en el modelo.

Se pueden considerar las interacciones de características entre Billing_Discrepancy_Yes y Anomaly_Score para capturar patrones matizados.

**Optimice los datos para las características moderadas:**

Usar Customer_Type_Residential y Payment_History_Overdue para agregar poder predictivo, pero asegúrese de que estén correctamente codificados y escalados.

Se pueden explorar combinaciones de Anomaly_Score y Geo_Area_Urban para ver si los factores de riesgo geográfico influyen en la detección de anomalías.

**Reevalúe las características de bajo impacto:**

De manera opcional evalúe si las características como Consumption_Peaks_Moderate o Meter_Type_Smart se pueden eliminar para simplificar el modelo sin una pérdida significativa de precisión.

Se puede investigar si las características de bajo impacto contribuyen a interacciones significativas con otras variables (por ejemplo, combinando Meter_Type_Smart con Billing_Discrepancy_Yes).

**Mejoras en la ingeniería de características:**

**Cree características derivadas, como:**

1.   **Puntuación de riesgo de fraude:** combinar las características principales en una puntuación de riesgo compuesta.

2.   **Patrones de consumo:** calcular las desviaciones del consumo típico para clientes similares.

# **Ajuste del modelo:**

Experimentar con modelos que manejan bien las relaciones no lineales, como Random Forests o Gradient Boosting (por ejemplo, XGBoost), aprovechando la importancia de las características principales para obtener mejores predicciones.

Utilizar técnicas de selección de características para validar si la eliminación de características de baja importancia mejora el rendimiento del modelo.
"""