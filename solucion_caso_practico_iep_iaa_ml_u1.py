# -*- coding: utf-8 -*-
"""Solucion_caso_practico_IEP-IAA-ML_u1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Sl3eIYdjRYLDrzMFF_m2TQ6K_FqJSRRv

Link de acceso solucion en Google Colab: https://colab.research.google.com/drive/1Sl3eIYdjRYLDrzMFF_m2TQ6K_FqJSRRv?usp=sharing

# **Enunciado**

**Clasificación**

En este caso práctico vamos a trabajar con modelos de aprendizaje automático supervisado de clasificación vistos en la lección 2.

**Datos**

Se proporcionan tres conjuntos de datos, con sus correspondientes clases.

***Carga los datasets***

Estos contienen tres variables, dos relativas a valores y una variable y que contiene la clase. Esta clase es binaria y valdrá cero o uno.

En el notebook se proporciona el código necesario para visualizar los datos con sus diferentes clases y el código para dividir los datos en conjunto de entrenamiento y test.  

**Modelos**

En cada uno de ellos deberás realizar lo siguiente:

1. Entrenar y predecir
2. Evaluar el rendimiento del modelo Los algoritmos propuestos son los siguientes
3. Analizar qué modelo funciona mejor y por qué

Los algoritmos propuestos son:

1. • Logistic Regression
2. • kNN
3. • SVM: Kernel lineal y radial
4. • Árbol de decisión
5. • Modelos de ensemble: Random Forest
6. • Modelos de Boosting: Gradient Boosting.

Para ello se proporciona el código del primer caso, Regresión Logística. https://drive.google.com/file/d/14gDv3u8N1wgeEOskL43I4AwAIIU3_D0C/view?usp=sharing

Deberás replicarlo, con los cambios pertinentes, para poder ejecutar los diferentes logaritmos. Una vez hayas trabajado con todos los diferentes algoritmos, analiza cuáles han funcionado mejor para cada caso y por qué.

# **Código**
"""

# Instalamos las librerías necesarias
!pip install scikit-learn matplotlib mlxtend seaborn

# Importamos las librerías necesarias
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

# Cargamos los datasets
df1 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/datos_IEP-IAA-ML_u1/df1.csv')
df2 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/datos_IEP-IAA-ML_u1/df2.csv')
df3 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/datos_IEP-IAA-ML_u1/df3.csv')

datasets = [df1, df2, df3]
datasets_names = ['df1', 'df2', 'df3']

# Dividimos los datos en entrenamiento y prueba
datasets_train = []
datasets_test = []
for df in datasets:
    df_train, df_test = train_test_split(df, test_size=0.2, stratify=df['y'], random_state=1993)
    datasets_train.append(df_train)
    datasets_test.append(df_test)

# Función para entrenar y evaluar los modelos
def train_and_evaluate(model, X_train, y_train, X_test, y_test):
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    return accuracy, precision, recall, f1

# Evaluamos los modelos en cada dataset
results = []
models = {
    'Logistic Regression': LogisticRegression(),
    'kNN': KNeighborsClassifier(),
    'SVM (Linear)': SVC(kernel='linear', probability=True),
    'SVM (RBF)': SVC(kernel='rbf', probability=True),
    'Decision Tree': DecisionTreeClassifier(),
    'Random Forest': RandomForestClassifier(),
    'Gradient Boosting': GradientBoostingClassifier()
}

for name, model in models.items():
    for i, (train, test) in enumerate(zip(datasets_train, datasets_test)):
        X_train, y_train = train[['X1', 'X2']], train['y']
        X_test, y_test = test[['X1', 'X2']], test['y']
        accuracy, precision, recall, f1 = train_and_evaluate(model, X_train, y_train, X_test, y_test)
        results.append({'Model': name, 'Dataset': datasets_names[i], 'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1 Score': f1})

# Convertimos los resultados a un DataFrame
results_df = pd.DataFrame(results)

# Mostramos los resultados en el notebook
print("Resultados de los modelos:")
print(results_df)

# Visualización de los resultados
# Gráfico comparativo de accuracy por dataset y modelo
plt.figure(figsize=(12, 6))
sns.barplot(data=results_df, x='Model', y='Accuracy', hue='Dataset', palette="viridis")
plt.title("Comparación de Accuracy por Dataset y Modelo")
plt.xlabel("Modelos")
plt.ylabel("Accuracy")
plt.xticks(rotation=45)
plt.legend(title="Dataset")
plt.tight_layout()
plt.show()

# Gráfico comparativo de F1 Score por dataset y modelo
plt.figure(figsize=(12, 6))
sns.barplot(data=results_df, x='Model', y='F1 Score', hue='Dataset', palette="rocket")
plt.title("Comparación de F1 Score por Dataset y Modelo")
plt.xlabel("Modelos")
plt.ylabel("F1 Score")
plt.xticks(rotation=45)
plt.legend(title="Dataset")
plt.tight_layout()
plt.show()

# Gráfico comparativo de Precision por dataset y modelo
plt.figure(figsize=(12, 6))
sns.barplot(data=results_df, x='Model', y='Precision', hue='Dataset', palette="coolwarm")
plt.title("Comparación de Precision por Dataset y Modelo")
plt.xlabel("Modelos")
plt.ylabel("Precision")
plt.xticks(rotation=45)
plt.legend(title="Dataset")
plt.tight_layout()
plt.show()

# Gráfico comparativo de Recall por dataset y modelo
plt.figure(figsize=(12, 6))
sns.barplot(data=results_df, x='Model', y='Recall', hue='Dataset', palette="mako")
plt.title("Comparación de Recall por Dataset y Modelo")
plt.xlabel("Modelos")
plt.ylabel("Recall")
plt.xticks(rotation=45)
plt.legend(title="Dataset")
plt.tight_layout()
plt.show()

"""# **Análisis del rendimiento por dataset:**

**Dataset 1 (df1):**

*Mejor modelo:* SVM (RBF) y SVM (Linear) obtuvieron la mejor precisión (Accuracy) de 0.920, ligeramente por encima de otros modelos como Gradient Boosting y Logistic Regression.

*Métrica complementaria:* En términos de F1 Score, el modelo SVM (RBF) también tiene un valor alto de 0.922, lo que indica un buen equilibrio entre precisión (Precision) y exhaustividad (Recall).

***Conclusión:*** Para df1, SVM (RBF) es el mejor modelo en términos de rendimiento general.

**Dataset 2 (df2):**

*Mejor modelo:* El modelo kNN logra la mejor precisión (Accuracy) de 0.870, seguido de cerca por SVM (RBF) con 0.865.

*Métrica complementaria:* El F1 Score del modelo kNN (0.871) también lo posiciona como la mejor opción para este dataset.

*Rendimiento pobre:* Modelos como Logistic Regression y SVM (Linear) tuvieron un rendimiento bajo, con precisiones de 0.480 y 0.510, respectivamente.

***Conclusión:*** Para df2, kNN es el modelo con mejor rendimiento, probablemente porque los datos no lineales se benefician de este enfoque.

**Dataset 3 (df3):**

*Mejor modelo:* El modelo Gradient Boosting tiene la mejor precisión (Accuracy) de 0.880, superando a los demás modelos.

*Métrica complementaria:* También tiene un excelente F1 Score de 0.878, destacándose como el modelo más robusto en este caso.

**Conclusión:** Para df3, Gradient Boosting es el modelo más adecuado, especialmente debido a su capacidad para capturar relaciones complejas en los datos.

# **Conclusiones generales:**

**Modelos más consistentes:**

SVM (RBF) y Gradient Boosting mostraron un rendimiento consistente en los tres datasets, adaptándose bien a datos lineales y no lineales.
kNN destacó en el dataset df2, lo que sugiere que funciona bien en conjuntos de datos con patrones locales.

**Impacto de los datos:**

El rendimiento de los modelos depende significativamente de la distribución y complejidad de los datos. Modelos simples como Logistic Regression funcionan bien en datos lineales (como df1), pero pierden rendimiento en conjuntos de datos más complejos.

**Modelos recomendados:**

Para tareas generales de clasificación, Gradient Boosting y SVM (RBF) suelen ser buenas opciones debido a su capacidad para manejar datos complejos y proporcionar un buen equilibrio entre precisión y flexibilidad.

"""