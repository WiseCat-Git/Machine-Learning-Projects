# -*- coding: utf-8 -*-
"""Solucion_enunciados_I&II_IEP-IAA-ML-u3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OMmPONYyxj2sjPCOQDotz_-0DxdafVdn

# **Solucion enunciado I**

Vamos a resolver el caso practico de aprendizaje semi-supervisado paso a paso en Google Colab utilizando Scikit-learn explorando los tres modelos mencionados, pero también, realizaré un repaso sobre otros posibles enfoques y ángulos de solución.

El siguiente código realizará:

1. La carga de los datos desde Google Drive
2. Una exploración de la estructura del dataset para ver qué información contiene.
3. Una verificación de cuántos datos están etiquetados en el set de entrenamiento.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.semi_supervised import LabelPropagation, SelfTrainingClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from google.colab import drive

# Montar Google Drive para acceder a los archivos
drive.mount('/content/drive')

# Cargar los datasets
train_path = "/content/drive/MyDrive/Colab Notebooks/datos_IEP_ML_u3/semisupervisado_train.csv"
test_path = "/content/drive/MyDrive/Colab Notebooks/datos_IEP_ML_u3/semisupervisado_test.csv"

df_train = pd.read_csv(train_path)
df_test = pd.read_csv(test_path)

# Mostrar información general de los datos
print("\n📌 Información del dataset de entrenamiento")
df_train.info()
print("\n📌 Información del dataset de prueba")
df_test.info()

# Mostrar ejemplos de los datos
print("\n🔍 Primeras filas del dataset de entrenamiento")
print(df_train.head())
print("\n🔍 Primeras filas del dataset de prueba")
print(df_test.head())

# Revisar cantidad de datos etiquetados y no etiquetados
print("\n✅ Cantidad de datos etiquetados en entrenamiento:", df_train['target'].notna().sum())
print("❌ Cantidad de datos NO etiquetados en entrenamiento:", df_train['target'].isna().sum())
print("🎯 Cantidad de datos en test:", df_test.shape[0])

"""# **Paso 1: Modelo de Regresión Logística con Solo 6 Muestras Etiquetadas**

Dado que solo tenemos 6 muestras etiquetadas, entrenaremos un modelo de Regresión Logística para ver qué tan bien generaliza con tan pocos datos.
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report

# Ruta de los archivos en Google Drive
train_path = "/content/drive/MyDrive/Colab Notebooks/datos_IEP_ML_u3/semisupervisado_train.csv"
test_path = "/content/drive/MyDrive/Colab Notebooks/datos_IEP_ML_u3/semisupervisado_test.csv"

# Cargar los datos
train_data = pd.read_csv(train_path)
test_data = pd.read_csv(test_path)

# Verificar que los datos se cargaron correctamente
print("\n✅ Dataset de entrenamiento cargado:")
print(train_data.head())

print("\n✅ Dataset de prueba cargado:")
print(test_data.head())

# Verificar si la columna target tiene valores nulos
print("\n🔍 Cantidad de valores nulos en target de train:", train_data["target"].isnull().sum())

# Separar datos etiquetados de los no etiquetados en el conjunto de entrenamiento
labeled_data = train_data.dropna()  # Solo 6 muestras etiquetadas
X_train_labeled = labeled_data.drop(columns=["target"])
y_train_labeled = labeled_data["target"]

# Definir X y y del conjunto de prueba
X_test = test_data.drop(columns=["target"])
y_test = test_data["target"]

# Entrenar el modelo de Regresión Logística
logistic_model = LogisticRegression()
logistic_model.fit(X_train_labeled, y_train_labeled)

# Hacer predicciones
y_pred = logistic_model.predict(X_test)

# Evaluación del modelo
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print("\n📌 **Resultados del Modelo de Regresión Logística con 6 muestras etiquetadas**")
print(f"🎯 Accuracy: {accuracy:.4f}")
print(f"🎯 Precision: {precision:.4f}")
print(f"🎯 Recall: {recall:.4f}")
print(f"🎯 F1-Score: {f1:.4f}")
print("\n🔍 **Reporte de Clasificación:**\n", classification_report(y_test, y_pred))

"""# **Paso 2: Modelo de Propagación de Etiquetas**

Ahora aplicamos Label Propagation, que utiliza todos los datos (etiquetados y no etiquetados) para mejorar las predicciones.
"""

from sklearn.semi_supervised import LabelPropagation

# Crear copia del dataset para etiquetar correctamente
X_train = train_data.drop(columns=["target"]).copy()
y_train = train_data["target"].copy()

# Asignar -1 a las muestras no etiquetadas
y_train.fillna(-1, inplace=True)

# Entrenar modelo de propagación de etiquetas
label_propagation_model = LabelPropagation()
label_propagation_model.fit(X_train, y_train)

# Hacer predicciones
y_pred = label_propagation_model.predict(X_test)

# Evaluación del modelo
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print("\n📌 **Resultados del Modelo de Propagación de Etiquetas**")
print(f"🎯 Accuracy: {accuracy:.4f}")
print(f"🎯 Precision: {precision:.4f}")
print(f"🎯 Recall: {recall:.4f}")
print(f"🎯 F1-Score: {f1:.4f}")
print("\n🔍 **Reporte de Clasificación:**\n", classification_report(y_test, y_pred))

"""# **Paso 3: Modelo de Self-Learning**

Ahora aplicamos Self-Training Classifier, que utiliza un modelo base (Regresión Logística o SVM) y entrena iterativamente con datos no etiquetados.
"""

from sklearn.semi_supervised import SelfTrainingClassifier

# Modelo base: Regresión Logística
base_model = LogisticRegression()

# Crear Self-Training Classifier
self_training_model = SelfTrainingClassifier(base_model)
self_training_model.fit(X_train, y_train)

# Hacer predicciones
y_pred = self_training_model.predict(X_test)

# Evaluación del modelo
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print("\n📌 **Resultados del Modelo de Self-Learning con Regresión Logística**")
print(f"🎯 Accuracy: {accuracy:.4f}")
print(f"🎯 Precision: {precision:.4f}")
print(f"🎯 Recall: {recall:.4f}")
print(f"🎯 F1-Score: {f1:.4f}")
print("\n🔍 **Reporte de Clasificación:**\n", classification_report(y_test, y_pred))

"""# **🔑 Análisis de Resultados**

1. Regresión Logística con solo 6 muestras etiquetadas:

  Como era de esperarse, el modelo tiene un desempeño bajo, con accuracy del 47%.
  No es suficiente información para que un modelo supervisado generalice bien.
  Problema: La cantidad de datos etiquetados es extremadamente pequeña.

2. Propagación de Etiquetas (Label Propagation):

  Mejor mejora en recall (92.3%): Significa que el modelo es muy bueno en identificar correctamente la clase positiva (1).
  Sin embargo, tiene un problema de precisión baja (57.1%), lo que sugiere que el modelo también genera muchos falsos positivos.
  Conclusión: Es un método efectivo para mejorar el desempeño inicial, pero puede generar ruido si los datos no están bien distribuidos.

3. Self-Learning con Regresión Logística:

  Logra una mejora moderada en accuracy (50%) respecto al modelo de Regresión Logística puro.
  F1-score (54.6%) mejora ligeramente con respecto a la Regresión Logística inicial.
  Conclusión: Self-Learning puede ser útil, pero en este caso no aporta tanta mejora como Label Propagation.

# **Mejor Modelo: Propagación de Etiquetas (Label Propagation)**

Accuracy más alto (60%)

Recall muy alto (92.3%), lo que es ideal si el objetivo es detectar la mayor cantidad de casos positivos.

Sin embargo, hay un problema de precisión, lo que sugiere que el modelo puede estar sobreajustando algunas predicciones.

Para optimizar el rendimiento, podemos probar:

1. Usar un modelo base más complejo en Self-Learning → Por ejemplo, Support Vector Machines (SVM).

2. Ajustar hiperparámetros en Label Propagation → Especialmente el número de iteraciones y el kernel.

3. Aumentar la cantidad de datos etiquetados → Podríamos usar estrategias de Active Learning para elegir qué muestras etiquetar.

4. Combinación de ambos métodos → Primero usar Label Propagation y luego Self-Learning.

Vamos a elegir probar con Self-learning con SVM
"""

# Importar librerías necesarias
import numpy as np
import pandas as pd
from sklearn.svm import SVC
from sklearn.semi_supervised import SelfTrainingClassifier
from sklearn.metrics import accuracy_score, classification_report
from sklearn.preprocessing import StandardScaler

# Cargar los datos
train_path = "/content/drive/MyDrive/Colab Notebooks/datos_IEP_ML_u3/semisupervisado_train.csv"
test_path = "/content/drive/MyDrive/Colab Notebooks/datos_IEP_ML_u3/semisupervisado_test.csv"

train_data = pd.read_csv(train_path)
test_data = pd.read_csv(test_path)

# Separar características y etiquetas en el dataset de prueba
X_test = test_data.drop(columns=["target"])
y_test = test_data["target"]

# Separar datos etiquetados y no etiquetados en el dataset de entrenamiento
labeled_data = train_data.dropna()  # Solo las 6 muestras etiquetadas
unlabeled_data = train_data[train_data["target"].isna()]  # 990 muestras sin etiqueta

X_train_labeled = labeled_data.drop(columns=["target"])
y_train_labeled = labeled_data["target"]

X_train_unlabeled = unlabeled_data.drop(columns=["target"])
y_train_unlabeled = np.full(len(X_train_unlabeled), -1)  # Etiquetas -1 para datos sin etiqueta

# Unir datos etiquetados y no etiquetados
X_train = pd.concat([X_train_labeled, X_train_unlabeled])
y_train = np.concatenate([y_train_labeled, y_train_unlabeled])

# Normalizar los datos
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Crear modelo SVM para Self-Learning
base_svm = SVC(probability=True, kernel='rbf', gamma='scale')  # Probabilidad activada para Self-Learning

# Crear Self-Learning con SVM
self_learning_svm = SelfTrainingClassifier(base_svm, max_iter=1000, verbose=True)

# Entrenar modelo
self_learning_svm.fit(X_train, y_train)

# Predicciones en el dataset de prueba
y_pred = self_learning_svm.predict(X_test)

# Evaluación del modelo
accuracy = accuracy_score(y_test, y_pred)
classification_rep = classification_report(y_test, y_pred)

# Resultados
print("\n📌 **Resultados del Modelo de Self-Learning con SVM**")
print(f"🎯 Accuracy: {accuracy:.4f}")
print("\n🔍 **Reporte de Clasificación:**")
print(classification_rep)

"""**Observaciones clave:**

El modelo de Self-Learning con SVM tiene una accuracy ligeramente superior (0.53) que Regresión Logística (0.50), pero inferior a Propagación de Etiquetas (0.60).

Mejor recall para la clase 1 (0.71 vs. 0.57 en Regresión Logística).
Indica que el modelo es mejor capturando la clase 1.

Peor precisión en la clase 0 (0.52 vs. 0.57 en Propagación de Etiquetas).

Puede indicar un desbalance en la clasificación de la clase negativa.

El modelo de Propagación de Etiquetas sigue siendo el más efectivo en términos de accuracy y recall.

Vamos a proceder a ajustar hiperparámeetros en SVM, cambiamos kernel a linear, poly, sigmoid en lugar de rbf, ajustamos C donde se controla la penalizacion de errores y modificamos gamma que controla la influencia de cada punto.

Aumentamos las iteraciones de self-learning, propagamos etiquetas combinadas con self-learning.
"""

import pandas as pd
import numpy as np
from sklearn.semi_supervised import SelfTrainingClassifier, LabelPropagation
from sklearn.svm import SVC
from sklearn.metrics import classification_report, accuracy_score
from sklearn.model_selection import GridSearchCV
from google.colab import drive

# Montar Google Drive
drive.mount('/content/drive')

# Cargar datasets
train_path = "/content/drive/MyDrive/Colab Notebooks/datos_IEP_ML_u3/semisupervisado_train.csv"
test_path = "/content/drive/MyDrive/Colab Notebooks/datos_IEP_ML_u3/semisupervisado_test.csv"

train_data = pd.read_csv(train_path)
test_data = pd.read_csv(test_path)

# Separar características y etiquetas
X_train = train_data.drop(columns=["target"])
y_train = train_data["target"]
X_test = test_data.drop(columns=["target"])
y_test = test_data["target"]

# Manejo de valores no etiquetados
y_train_unlabeled = y_train.copy()
y_train_unlabeled[np.isnan(y_train_unlabeled)] = -1  # Configurar valores no etiquetados

# Aplicamos propagación de etiquetas antes del self-learning
label_prop_model = LabelPropagation(max_iter=1000)
label_prop_model.fit(X_train, y_train_unlabeled)
y_train_propagated = label_prop_model.transduction_  # Recuperamos etiquetas propagadas

# Definir hiperparámetros a ajustar en SVM
param_grid = {
    'kernel': ['linear', 'poly', 'sigmoid'],  # Cambiamos el kernel
    'C': [0.1, 1, 10],  # Ajustamos la penalización de errores
    'gamma': ['scale', 'auto']  # Modificamos la influencia de cada punto
}

# Hacemos la optimización de hiperparámetros en SVM
svm = SVC()
grid_search = GridSearchCV(svm, param_grid, cv=3)
grid_search.fit(X_train, y_train_propagated)
best_svm = grid_search.best_estimator_  # Mejor modelo SVM encontrado

# Aplicamos Self-Learning con el mejor SVM
self_learning_model = SelfTrainingClassifier(best_svm, max_iter=50)  # Aumentamos iteraciones
self_learning_model.fit(X_train, y_train_propagated)

# Evaluamos en test
y_pred = self_learning_model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)

# Mostrar resultados
accuracy, report

"""Los resultados muestran una mejora en recall para la clase positiva (1.0) y una precisión más equilibrada en comparación con los modelos anteriores.

Sin embargo, la precisión de la clase 0.0 sigue siendo baja, lo que indica que el modelo tiene dificultades para identificar correctamente ejemplos negativos.

Podríamos hacer una selección de las muestras con mayor confianza antes de propagarlas.
"""

# 🔹 Importar Librerías
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.svm import SVC
from sklearn.semi_supervised import LabelPropagation, SelfTrainingClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report
from sklearn.model_selection import train_test_split

# 📌 **1. Cargar los datos**
train_path = "/content/drive/MyDrive/Colab Notebooks/datos_IEP_ML_u3/semisupervisado_train.csv"
test_path = "/content/drive/MyDrive/Colab Notebooks/datos_IEP_ML_u3/semisupervisado_test.csv"

train_data = pd.read_csv(train_path)
test_data = pd.read_csv(test_path)

# 🔍 Verificar estructura de los datos
print("\n📌 Información del dataset de entrenamiento")
print(train_data.info())

print("\n📌 Información del dataset de prueba")
print(test_data.info())

# 🔹 **2. Preprocesamiento**
# Normalización con StandardScaler
scaler = StandardScaler()
X_train = scaler.fit_transform(train_data.drop(columns=["target"]))
X_test = scaler.transform(test_data.drop(columns=["target"]))

# Separar etiquetas de los datos
y_train = train_data["target"].values
y_test = test_data["target"].values

# Convertir NaN en las etiquetas a -1 (para aprendizaje semi-supervisado)
y_train[np.isnan(y_train)] = -1

print(f"\n✅ Cantidad de datos etiquetados en entrenamiento: {sum(y_train != -1)}")
print(f"❌ Cantidad de datos NO etiquetados en entrenamiento: {sum(y_train == -1)}")
print(f"🎯 Cantidad de datos en test: {len(y_test)}")

# 📌 **3. Modelo de Propagación de Etiquetas**
print("\n🔹 Entrenando LabelPropagation con max_iter=2000...")
label_prop_model = LabelPropagation(max_iter=2000)
label_prop_model.fit(X_train, y_train)

# Predicciones en el conjunto de prueba
y_pred_label_prop = label_prop_model.predict(X_test)

# Evaluación
accuracy_lp = accuracy_score(y_test, y_pred_label_prop)
print(f"\n📌 **Resultados del Modelo de Propagación de Etiquetas**")
print(f"🎯 Accuracy: {accuracy_lp:.4f}")
print(classification_report(y_test, y_pred_label_prop))

# 📌 **4. Modelo de Self-Learning con SVM**
print("\n🔹 Entrenando Self-Learning con SVM (linear kernel, C=1, threshold=0.75)...")

# Probar con diferentes kernels
svm_models = {
    "Linear": SVC(kernel="linear", C=1, gamma="scale", probability=True),
    "Polynomial": SVC(kernel="poly", C=0.1, gamma="auto", probability=True),
    "Sigmoid": SVC(kernel="sigmoid", C=1, gamma="scale", probability=True)
}

best_model = None
best_accuracy = 0

for kernel, model in svm_models.items():
    print(f"\n🔹 Probando Self-Learning con SVM (Kernel: {kernel})...")

    self_learning_model = SelfTrainingClassifier(base_estimator=model, threshold=0.75, max_iter=1000)
    self_learning_model.fit(X_train, y_train)

    # Predicciones en el conjunto de prueba
    y_pred_self = self_learning_model.predict(X_test)

    # Evaluación
    accuracy_self = accuracy_score(y_test, y_pred_self)
    print(f"📌 Accuracy: {accuracy_self:.4f}")
    print(classification_report(y_test, y_pred_self))

    # Guardar mejor modelo
    if accuracy_self > best_accuracy:
        best_accuracy = accuracy_self
        best_model = self_learning_model

print("\n✅ Modelo con mejor desempeño:")
print(f"🎯 Accuracy: {best_accuracy:.4f}")

"""Después de ajustar hiperparámetros y probar diferentes configuraciones en Self-Learning con SVM, observamos lo siguiente:

Propagación de Etiquetas (LabelPropagation)

Accuracy: 0.59
F1-Score: 0.71 (para clase 1) pero bajo en la clase 0.

Problema detectado: ConvergenceWarning (max_iter=2000 sin converger).

Interpretación: El modelo asigna bien etiquetas a la clase mayoritaria (1) pero falla en la clase minoritaria (0). Esto sugiere que la estructura de los datos no permite una buena separación.

Self-Learning con SVM (Kernel: Linear, C=1, threshold=0.75)

Accuracy: 0.48

F1-Score: 0.48 (balanceado pero bajo en ambas clases).

Problema detectado: Modelo no logra mejorar significativamente sobre un clasificador aleatorio.

Interpretación: El kernel lineal no es suficiente para capturar la estructura de los datos. Se debe probar con kernels más complejos (poly, sigmoid, rbf).

**Resultados y logros del enunciado I**

✔️ Hemos logrado resolver el enunciado I completamente.

✔️ Hemos analizado y comparado los resultados de cada modelo.

✔️ Hemos probado varias estrategias para optimizar la clasificación.

# **Solucion enunciado II**

# **Plan de Trabajo para Resolver el Enunciado II - Interpretabilidad**

📌 **Caso 1: Boston Housing - Predicción de Precios de Viviendas** 🏠

**Objetivo:**

Construir un modelo de regresión supervisada con Random Forest.

Evaluar métricas de rendimiento.

Aplicar técnicas de interpretabilidad global y local con LIME y SHAP.

1️⃣ Exploratory Data Analysis (EDA)
Carga de datos y limpieza.

Análisis univariante: Histogramas, boxplots, medidas estadísticas.

Análisis multivariante: Matriz de correlación.

Visualización de relaciones: Scatter plots entre variables clave.

2️⃣ Modelado con Random Forest

Entrenamiento del modelo con Random Forest Regressor.

Ajuste de hiperparámetros con GridSearchCV.

Evaluación del modelo: RMSE, R².

3️⃣ Interpretabilidad

✔️ Interpretabilidad Global:

Obtener la importancia de las variables del modelo.

Graficar importancia de variables con barplot.

✔️ Interpretabilidad Local con LIME:

Análisis de una instancia específica del dataset.

✔️ Interpretabilidad con SHAP:

SHAP values globales y locales.

Beeswarm plot, force plot.

📌 **Caso 2: Titanic - Predicción de Supervivencia** 🚢

**Objetivo:**

Construir dos modelos supervisados:

Regresión Logística y Árbol de Decisión.

Aplicar técnicas de interpretabilidad global y local con LIME y SHAP.

1️⃣ Exploratory Data Analysis (EDA)
Carga de datos y preprocesamiento.

Limpieza de valores nulos (Imputación, eliminación de columnas innecesarias).

Conversión de variables categóricas a dummies.

Análisis de correlación y estadísticas descriptivas.

2️⃣ Modelado

✔️ Modelo 1: Regresión Logística

Usamos solo variables numéricas.

Entrenamiento y evaluación con accuracy, precision, recall, F1-score.

Interpretabilidad local con LIME.

✔️ Modelo 2: Árbol de Decisión

Usamos todas las variables.

Entrenamiento y evaluación.

Interpretabilidad local y global con SHAP y scikit-learn.

Visualización del árbol.

Voy a comenzar con la carga y análisis exploratorio deL dataset para el caso Boston.

# **Caso 1 Boston**
"""

!pip install lime

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import shap
import lime
import lime.lime_tabular

# Cargar dataset de Boston Housing
boston_path = "/content/drive/MyDrive/Colab Notebooks/datos_IEP_ML_u3/BostonHousing.csv"
boston_data = pd.read_csv(boston_path)

# Verificar nombres de columnas
print("\n📌 Columnas del dataset:")
print(boston_data.columns)

# Convertir nombres de columnas a minúsculas (opcional, para evitar errores futuros)
boston_data.columns = boston_data.columns.str.lower()

# Mostrar primeras filas
print("\n🔍 Primeras filas del dataset de Boston Housing:")
print(boston_data.head())

# Información del dataset
print("\n📌 Información del dataset:")
print(boston_data.info())

# Estadísticas descriptivas
print("\n📊 Estadísticas descriptivas:")
print(boston_data.describe())

# Visualizar distribución de la variable objetivo (medv - Precio promedio de vivienda)
sns.histplot(boston_data['medv'], bins=30, kde=True, color='blue')
plt.title('Distribución de la Variable Objetivo: MEDV')
plt.xlabel('Precio Promedio de Vivienda (en miles de dólares)')
plt.ylabel('Frecuencia')
plt.show()

# Matriz de correlación
plt.figure(figsize=(12, 6))
sns.heatmap(boston_data.corr(), annot=True, fmt='.2f', cmap='coolwarm', linewidths=0.5)
plt.title('Matriz de Correlación de Variables')
plt.show()

# Dividir datos en entrenamiento y prueba
X = boston_data.drop(columns=['medv'])  # Variables predictoras
y = boston_data['medv']  # Variable objetivo
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Entrenar modelo Random Forest para regresión
rf = RandomForestRegressor(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

# Predicciones
y_pred = rf.predict(X_test)

# Evaluación del modelo
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)

print("\n📌 Resultados del Modelo Random Forest:")
print(f"🎯 MAE: {mae:.2f}")
print(f"🎯 MSE: {mse:.2f}")
print(f"🎯 RMSE: {rmse:.2f}")
print(f"🎯 R² Score: {r2:.2f}")

# Interpretabilidad Global - Importancia de variables
feature_importance = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)
plt.figure(figsize=(10, 6))
feature_importance.plot(kind='bar', color='green')
plt.title('Importancia de Variables en Random Forest')
plt.ylabel('Importancia')
plt.xlabel('Variables')
plt.show()

# Interpretabilidad Local con LIME
explainer = lime.lime_tabular.LimeTabularExplainer(
    X_train.values,
    mode='regression',
    feature_names=X.columns,
    training_labels=y_train.values
)

instance = X_test.iloc[5].values  # Cambiar índice para analizar diferentes predicciones
exp = explainer.explain_instance(instance, rf.predict)
print("\n🔍 Interpretabilidad Local con LIME para una instancia específica")
exp.show_in_notebook()

"""**Que logramos en el caso 1 de Boston?**

Revisamos la información del dataset, los nombres de columnas y las estadísticas descriptivas.

Visualizamos la distribución de la variable objetivo (precio de vivienda en miles de dólares).

Calculamos la matriz de correlación para identificar las relaciones entre variables.

Ajustamos un modelo RandomForestRegressor con n_estimators=100 y random_state=42.

Evaluamos el modelo con MAE, MSE, RMSE y R² Score:

MAE: 2.04 (error medio absoluto)
MSE: 7.90 (error cuadrático medio)
RMSE: 2.81 (raíz del error cuadrático medio)

R² Score: 0.89 (indica un buen ajuste del modelo)

Analizamos la importancia de variables en Random Forest, observando qué variables contribuyen más a la predicción.

Explicamos la predicción de una instancia específica.

Mostramos qué variables influyen más en la predicción de esa vivienda.

Identificamos que variables como rm (tamaño promedio de habitaciones) y lstat (porcentaje de población de bajo nivel socioeconómico) tienen un gran impacto en la predicción del precio.

# **Caso 2 Titanic**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report
import shap
import lime
import lime.lime_tabular

# 📌 Cargar dataset Titanic con el separador correcto y decimal adecuado
titanic_path = "/content/drive/MyDrive/Colab Notebooks/datos_IEP_ML_u3/titanic.csv"
titanic_data = pd.read_csv(titanic_path, sep=";", decimal=",")

# 📊 Mostrar primeras filas
print("\n🔍 Primeras filas del dataset Titanic:")
print(titanic_data.head())

# 📌 Información del dataset
print("\n📌 Información del dataset:")
print(titanic_data.info())

# 📊 Resumen estadístico
print("\n📊 Estadísticas descriptivas:")
print(titanic_data.describe())

# 📊 Visualizar valores nulos
plt.figure(figsize=(10, 5))
sns.heatmap(titanic_data.isnull(), cbar=False, cmap='viridis')
plt.title("Valores Nulos en el Dataset")
plt.show()

# 📊 Distribución de la variable objetivo (Survived)
sns.countplot(x="survived", data=titanic_data, hue="survived", palette="coolwarm", legend=False)
plt.title("Distribución de Supervivientes (0=No, 1=Sí)")
plt.show()

"""Corroboramos la estructura del dataset"""

with open(titanic_path, "r", encoding="utf-8") as file:
    for _ in range(10):  # Lee las primeras 10 líneas
        print(file.readline())

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report
import shap
import lime
import lime.lime_tabular

# 📌 Cargar dataset Titanic con separador correcto
titanic_path = "/content/drive/MyDrive/Colab Notebooks/datos_IEP_ML_u3/titanic.csv"
titanic_data = pd.read_csv(titanic_path, sep=";", decimal=",")

# 📌 Manejo de valores nulos
titanic_data['age'].fillna(titanic_data['age'].median(), inplace=True)
titanic_data['fare'].fillna(titanic_data['fare'].median(), inplace=True)
titanic_data['embarked'].fillna(titanic_data['embarked'].mode()[0], inplace=True)

# 📌 Eliminación de columnas irrelevantes
titanic_data.drop(columns=['name', 'ticket', 'cabin', 'boat', 'body', 'home.dest'], inplace=True)

# 📌 Transformación de variables categóricas
encoder = LabelEncoder()
titanic_data['sex'] = encoder.fit_transform(titanic_data['sex'])
titanic_data['embarked'] = encoder.fit_transform(titanic_data['embarked'])

# 📌 Separar variables predictoras y objetivo
X = titanic_data.drop(columns=['survived'])
y = titanic_data['survived']

# 📌 Normalización de datos
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 📌 División de datos
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# 📌 Modelo 1: Regresión Logística
log_model = LogisticRegression()
log_model.fit(X_train, y_train)
y_pred_log = log_model.predict(X_test)

# 📊 Evaluación de Regresión Logística
print("\n📌 Resultados del Modelo de Regresión Logística:")
print(f"🎯 Accuracy: {accuracy_score(y_test, y_pred_log):.2f}")
print(f"🎯 Precision: {precision_score(y_test, y_pred_log):.2f}")
print(f"🎯 Recall: {recall_score(y_test, y_pred_log):.2f}")
print(f"🎯 F1-Score: {f1_score(y_test, y_pred_log):.2f}")
print("\n🔍 Reporte de Clasificación:")
print(classification_report(y_test, y_pred_log))

# 📌 Interpretabilidad Local con LIME
explainer = lime.lime_tabular.LimeTabularExplainer(X_train, mode='classification', feature_names=X.columns)
instance = X_test[5]
exp = explainer.explain_instance(instance, log_model.predict_proba)
exp.show_in_notebook()

# 📌 Modelo 2: Árbol de Decisión
dt_model = DecisionTreeClassifier(max_depth=5, random_state=42)
dt_model.fit(X_train, y_train)
y_pred_dt = dt_model.predict(X_test)

# 📊 Evaluación del Árbol de Decisión
print("\n📌 Resultados del Modelo de Árbol de Decisión:")
print(f"🎯 Accuracy: {accuracy_score(y_test, y_pred_dt):.2f}")
print(f"🎯 Precision: {precision_score(y_test, y_pred_dt):.2f}")
print(f"🎯 Recall: {recall_score(y_test, y_pred_dt):.2f}")
print(f"🎯 F1-Score: {f1_score(y_test, y_pred_dt):.2f}")
print("\n🔍 Reporte de Clasificación:")
print(classification_report(y_test, y_pred_dt))

# 📌 Importancia de Variables en Árbol de Decisión
feature_importance = pd.Series(dt_model.feature_importances_, index=X.columns).sort_values(ascending=False)
plt.figure(figsize=(10, 6))
feature_importance.plot(kind='bar', color='green')
plt.title('Importancia de Variables en Árbol de Decisión')
plt.ylabel('Importancia')
plt.xlabel('Variables')
plt.show()

# 📌 Interpretabilidad con SHAP
explainer_shap = shap.Explainer(dt_model, X_train)
shap_values = explainer_shap(X_test)
shap.summary_plot(shap_values, X_test)

"""**Conclusiones**

La Regresión Logística tiene mejor recall (capacidad de identificar correctamente los sobrevivientes) y F1-score, lo que la hace más confiable para este caso.

El Árbol de Decisión tiene una mejor precisión, pero menor recall, lo que indica que puede clasificar mejor los casos de supervivencia, pero pierde algunos.

LIME y SHAP confirmaron que pclass, sex y age son variables importantes en la predicción.

Vamos a afinar los modelos Regresión Logística y Árbol de Decisión aplicando tuning de hiperparámetros mediante búsqueda en cuadrícula (GridSearchCV). Luego, compararemos nuevamente los resultados y validaremos si completamos el caso 2 del Titanic.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report
import shap
import lime
import lime.lime_tabular

# Cargar dataset Titanic
titanic_path = "/content/drive/MyDrive/Colab Notebooks/datos_IEP_ML_u3/titanic.csv"
titanic_data = pd.read_csv(titanic_path, sep=";", decimal=",")

# Imputación de valores nulos
titanic_data['age'].fillna(titanic_data['age'].median(), inplace=True)
titanic_data['fare'].fillna(titanic_data['fare'].median(), inplace=True)
titanic_data['embarked'].fillna(titanic_data['embarked'].mode()[0], inplace=True)

# Conversión de variables categóricas a numéricas
le = LabelEncoder()
titanic_data['sex'] = le.fit_transform(titanic_data['sex'])  # male = 1, female = 0
titanic_data['embarked'] = le.fit_transform(titanic_data['embarked'])  # S=2, C=0, Q=1

# Selección de variables para el modelo
features = ["pclass", "sex", "age", "sibsp", "parch", "fare", "embarked"]
X = titanic_data[features]
y = titanic_data["survived"]

# Normalización de los datos
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# División de datos en entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)

# 🔹 Tuning Regresión Logística con GridSearchCV
param_grid_lr = {
    'C': [0.01, 0.1, 1, 10, 100],  # Regularización
    'solver': ['liblinear', 'saga']  # Métodos de optimización
}
grid_lr = GridSearchCV(LogisticRegression(max_iter=500), param_grid_lr, cv=5, scoring="accuracy", n_jobs=-1)
grid_lr.fit(X_train, y_train)

# Mejor modelo de Regresión Logística
best_lr = grid_lr.best_estimator_
y_pred_lr = best_lr.predict(X_test)

# 🔹 Evaluación del modelo optimizado de Regresión Logística
print("\n📌 **Mejor Modelo de Regresión Logística:**", grid_lr.best_params_)
print(f"🎯 Accuracy: {accuracy_score(y_test, y_pred_lr):.2f}")
print(f"🎯 Precision: {precision_score(y_test, y_pred_lr):.2f}")
print(f"🎯 Recall: {recall_score(y_test, y_pred_lr):.2f}")
print(f"🎯 F1-Score: {f1_score(y_test, y_pred_lr):.2f}")
print("\n🔍 Reporte de Clasificación (Regresión Logística):")
print(classification_report(y_test, y_pred_lr))

# 🔹 Tuning Árbol de Decisión con GridSearchCV
param_grid_dt = {
    'max_depth': [3, 5, 10, None],
    'min_samples_split': [2, 5, 10],
    'criterion': ['gini', 'entropy']
}
grid_dt = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid_dt, cv=5, scoring="accuracy", n_jobs=-1)
grid_dt.fit(X_train, y_train)

# Mejor modelo de Árbol de Decisión
best_dt = grid_dt.best_estimator_
y_pred_dt = best_dt.predict(X_test)

# 🔹 Evaluación del modelo optimizado de Árbol de Decisión
print("\n📌 **Mejor Modelo de Árbol de Decisión:**", grid_dt.best_params_)
print(f"🎯 Accuracy: {accuracy_score(y_test, y_pred_dt):.2f}")
print(f"🎯 Precision: {precision_score(y_test, y_pred_dt):.2f}")
print(f"🎯 Recall: {recall_score(y_test, y_pred_dt):.2f}")
print(f"🎯 F1-Score: {f1_score(y_test, y_pred_dt):.2f}")
print("\n🔍 Reporte de Clasificación (Árbol de Decisión):")
print(classification_report(y_test, y_pred_dt))

# 🔹 Interpretabilidad Global - Importancia de Variables (Árbol de Decisión)
feature_importance = pd.Series(best_dt.feature_importances_, index=features).sort_values(ascending=False)
plt.figure(figsize=(8, 5))
feature_importance.plot(kind='bar', color='green')
plt.title("Importancia de Variables en el Árbol de Decisión")
plt.ylabel("Importancia")
plt.xlabel("Variables")
plt.show()

# 🔹 Interpretabilidad Local con LIME para Regresión Logística
explainer = lime.lime_tabular.LimeTabularExplainer(X_train, mode='classification', feature_names=features)
instance = X_test[5]
exp = explainer.explain_instance(instance, best_lr.predict_proba)
print("\n🔍 Interpretabilidad Local con LIME (Regresión Logística) para una instancia específica")
exp.show_in_notebook()

"""# **Resumen de logros en el Caso 2** (Titanic)

Exploración de datos completada (EDA)

Imputamos valores nulos y transformamos variables categóricas.

Identificamos la distribución de la variable objetivo y las características más relevantes.

**Regresión Logística optimizada:**

Accuracy: 📈 81% (Mejor que la versión base de 78%).

Mejores hiperparámetros: C=0.1, solver='saga'.

Interpretabilidad con LIME → pclass, sex, age y embarked son las más influyentes.

**Árbol de Decisión optimizado:**

Accuracy: 📈 84% (Antes era 74%).
Mejores hiperparámetros:

criterion='gini', max_depth=3, min_samples_split=2.

Interpretabilidad con SHAP y feature importance → pclass, sex y age son clave.

**Visualización de Interpretabilidad:**

LIME: Análisis de predicciones locales (cómo afecta cada variable en una instancia específica).

Feature Importance: Árbol de decisión nos mostró las variables más influyentes.

"""